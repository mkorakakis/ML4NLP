{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bPiS2ExZ_K1W",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import BertTokenizer, BertForQuestionAnswering, BertConfig, AutoTokenizer, AutoModel\n",
    "\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import IntegratedGradients, LayerConductance, LayerIntegratedGradients, Saliency, NoiseTunnel\n",
    "from captum.attr import configure_interpretable_embedding_layer, remove_interpretable_embedding_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_input_ref_pair(question, text, ref_token_id, sep_token_id, cls_token_id):\n",
    "    question_ids = tokenizer.encode(question, add_special_tokens=False)\n",
    "    text_ids = tokenizer.encode(text, add_special_tokens=False)\n",
    "    input_ids = [cls_token_id] + question_ids + [sep_token_id] + text_ids + [sep_token_id]\n",
    "    ref_input_ids = [cls_token_id] + [ref_token_id] * len(question_ids) + [sep_token_id] + [ref_token_id] * len(text_ids) + [sep_token_id]\n",
    "\n",
    "    return torch.tensor([input_ids], device=device), torch.tensor([ref_input_ids], device=device), len(question_ids)\n",
    "\n",
    "def construct_input_ref_token_type_pair(input_ids, sep_ind=0):\n",
    "    sequence_length = input_ids.size(1)\n",
    "    token_type_ids = torch.tensor([[0 if i <= sep_ind else 1 for i in range(sequence_length)]], device=device)\n",
    "    ref_token_type_ids = torch.zeros_like(token_type_ids, device=device)\n",
    "    \n",
    "    return token_type_ids, ref_token_type_ids\n",
    "\n",
    "def construct_input_ref_pos_id_pair(input_ids):\n",
    "    sequence_length = input_ids.size(1)\n",
    "    position_ids = torch.arange(sequence_length, dtype=torch.long, device=device)\n",
    "    ref_position_ids = torch.zeros(sequence_length, dtype=torch.long, device=device)\n",
    "    position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    ref_position_ids = ref_position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    \n",
    "    return position_ids, ref_position_ids\n",
    "    \n",
    "def construct_attention_mask(input_ids):\n",
    "    return torch.ones_like(input_ids)\n",
    "\n",
    "def construct_bert_sub_embedding(input_ids, ref_input_ids, token_type_ids, ref_token_type_ids, position_ids, ref_position_ids):\n",
    "    input_embeddings = interpretable_embedding1.indices_to_embeddings(input_ids)\n",
    "    ref_input_embeddings = interpretable_embedding1.indices_to_embeddings(ref_input_ids)\n",
    "    input_embeddings_token_type = interpretable_embedding2.indices_to_embeddings(token_type_ids)\n",
    "    ref_input_embeddings_token_type = interpretable_embedding2.indices_to_embeddings(ref_token_type_ids)\n",
    "    input_embeddings_position_ids = interpretable_embedding3.indices_to_embeddings(position_ids)\n",
    "    ref_input_embeddings_position_ids = interpretable_embedding3.indices_to_embeddings(ref_position_ids)\n",
    "    \n",
    "    return (input_embeddings, ref_input_embeddings), (input_embeddings_token_type, ref_input_embeddings_token_type), (input_embeddings_position_ids, ref_input_embeddings_position_ids)\n",
    "    \n",
    "def construct_whole_bert_embeddings(input_ids, ref_input_ids, token_type_ids=None, ref_token_type_ids=None, position_ids=None, ref_position_ids=None):\n",
    "    input_embeddings = interpretable_embedding.indices_to_embeddings(input_ids, token_type_ids=token_type_ids, position_ids=position_ids)\n",
    "    ref_input_embeddings = interpretable_embedding.indices_to_embeddings(ref_input_ids, token_type_ids=token_type_ids, position_ids=position_ids)\n",
    "    \n",
    "    return input_embeddings, ref_input_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squad_pos_forward_func(inputs, token_type_ids=None, position_ids=None, attention_mask=None, position=0):\n",
    "    prediction = predict(inputs, token_type_ids=token_type_ids, position_ids=position_ids, attention_mask=attention_mask)\n",
    "    prediction = prediction[position]\n",
    "    \n",
    "    return prediction.max(1).values\n",
    "\n",
    "def predict(inputs, token_type_ids=None, position_ids=None, attention_mask=None):\n",
    "    return model(inputs, token_type_ids=token_type_ids, position_ids=position_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_attributions(attributions):\n",
    "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    \n",
    "    return attributions\n",
    "\n",
    "def get_top_attributed_tokens(attrs, k=5):\n",
    "    values, indices = torch.topk(attrs, k)\n",
    "    top_tokens = [all_tokens[idx] for idx in indices]\n",
    "    \n",
    "    return top_tokens, values, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_squad(data_file):\n",
    "    with open(data_file) as f:\n",
    "        data = json.load(f)['data']\n",
    "    rows = []\n",
    "    for article in data:\n",
    "        for paragraph in article['paragraphs']:\n",
    "            context = paragraph['context']\n",
    "            for qa in paragraph['qas']:\n",
    "                id_, question, answers = qa['id'], qa['question'], qa['answers']\n",
    "                answers = [a['text'] for a in answers]\n",
    "                rows.append((id_, context, question, answers))\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = process_squad(\"dev-v2.0.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "87Nj3oGH_pU2"
   },
   "outputs": [],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad', force_download=True)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters(): \n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.bert.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s-boqfGsBjb_"
   },
   "outputs": [],
   "source": [
    "ref_token_id = tokenizer.pad_token_id\n",
    "sep_token_id = tokenizer.sep_token_id\n",
    "cls_token_id = tokenizer.cls_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z5PiX9-yBn3S"
   },
   "outputs": [],
   "source": [
    "lig = LayerIntegratedGradients(squad_pos_forward_func, model.bert.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OCGp7lGX9JZB"
   },
   "outputs": [],
   "source": [
    "for example in dataset:\n",
    "    text = example[1]\n",
    "    question = example[2]\n",
    "    answers = example[3]\n",
    "\n",
    "    input_ids, ref_input_ids, sep_id = construct_input_ref_pair(question, text, ref_token_id, sep_token_id, cls_token_id)\n",
    "    token_type_ids, ref_token_type_ids = construct_input_ref_token_type_pair(input_ids, sep_id)\n",
    "    position_ids, ref_position_ids = construct_input_ref_pos_id_pair(input_ids)\n",
    "    attention_mask = construct_attention_mask(input_ids)\n",
    "\n",
    "    indices = input_ids[0].detach().tolist()\n",
    "    all_tokens = tokenizer.convert_ids_to_tokens(indices)\n",
    "\n",
    "    ground_truth = answers[0]\n",
    "\n",
    "    ground_truth_tokens = tokenizer.encode(ground_truth, add_special_tokens=False)\n",
    "    ground_truth_end_ind = indices.index(ground_truth_tokens[-1])\n",
    "    ground_truth_start_ind = ground_truth_end_ind - len(ground_truth_tokens) + 1\n",
    "\n",
    "    start_scores, end_scores = predict(input_ids, token_type_ids=token_type_ids, position_ids=position_ids, attention_mask=attention_mask)\n",
    "\n",
    "\n",
    "    print('Question: ', question)\n",
    "    print(start_scores)\n",
    "    print(end_scores)\n",
    "    print('Predicted Answer: ', ' '.join(all_tokens[torch.argmax(start_scores) : torch.argmax(end_scores)+1]))\n",
    "\n",
    "    attributions_start, delta_start = lig.attribute(inputs=input_ids, baselines=ref_input_ids, \n",
    "                                                    additional_forward_args=(token_type_ids, position_ids, attention_mask, 0),\n",
    "                                                    return_convergence_delta=True)\n",
    "    attributions_end, delta_end = lig.attribute(inputs=input_ids, baselines=ref_input_ids, \n",
    "                                                    additional_forward_args=(token_type_ids, position_ids, attention_mask, 1),\n",
    "                                                    return_convergence_delta=True)\n",
    "    \n",
    "    attributions_start_sum = summarize_attributions(attributions_start)\n",
    "    attributions_end_sum = summarize_attributions(attributions_end)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saliency = Saliency(squad_pos_forward_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in dataset:\n",
    "\n",
    "    text = example[1]\n",
    "    question = example[2]\n",
    "    answers = example[3]\n",
    "\n",
    "    input_ids, ref_input_ids, sep_id = construct_input_ref_pair(question, text, ref_token_id, sep_token_id, cls_token_id)\n",
    "    token_type_ids, ref_token_type_ids = construct_input_ref_token_type_pair(input_ids, sep_id)\n",
    "    position_ids, ref_position_ids = construct_input_ref_pos_id_pair(input_ids)\n",
    "    attention_mask = construct_attention_mask(input_ids)\n",
    "\n",
    "    indices = input_ids[0].detach().tolist()\n",
    "    all_tokens = tokenizer.convert_ids_to_tokens(indices)\n",
    "\n",
    "\n",
    "    ground_truth = answers[0]\n",
    "\n",
    "    ground_truth_tokens = tokenizer.encode(ground_truth, add_special_tokens=False)\n",
    "    ground_truth_end_ind = indices.index(ground_truth_tokens[-1])\n",
    "    ground_truth_start_ind = ground_truth_end_ind - len(ground_truth_tokens) + 1\n",
    "\n",
    "    start_scores, end_scores = predict(input_ids, token_type_ids=token_type_ids, position_ids=position_ids, attention_mask=attention_mask)\n",
    "\n",
    "\n",
    "    print('Question: ', question)\n",
    "    print(start_scores)\n",
    "    print(end_scores)\n",
    "    print('Predicted Answer: ', ' '.join(all_tokens[torch.argmax(start_scores) : torch.argmax(end_scores)+1]))\n",
    "\n",
    "    attributions_start = saliency.attribute(inputs=input_ids, \n",
    "                                            additional_forward_args=(token_type_ids, position_ids, attention_mask, 0))\n",
    "    attributions_end = saliency.attribute(inputs=input_ids, baselines=ref_input_ids, \n",
    "                                            additional_forward_args=(token_type_ids, position_ids, attention_mask, 1))\n",
    "    \n",
    "    attributions_start_sum = summarize_attributions(attributions_start)\n",
    "    attributions_end_sum = summarize_attributions(attributions_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt = NoiseTunnel(ig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in dataset:\n",
    "    \n",
    "    text = example[1]\n",
    "    question = example[2]\n",
    "    answers = example[3]\n",
    "\n",
    "    input_ids, ref_input_ids, sep_id = construct_input_ref_pair(question, text, ref_token_id, sep_token_id, cls_token_id)\n",
    "    token_type_ids, ref_token_type_ids = construct_input_ref_token_type_pair(input_ids, sep_id)\n",
    "    position_ids, ref_position_ids = construct_input_ref_pos_id_pair(input_ids)\n",
    "    attention_mask = construct_attention_mask(input_ids)\n",
    "\n",
    "    indices = input_ids[0].detach().tolist()\n",
    "    all_tokens = tokenizer.convert_ids_to_tokens(indices)\n",
    "\n",
    "\n",
    "    ground_truth = answers[0]\n",
    "\n",
    "    ground_truth_tokens = tokenizer.encode(ground_truth, add_special_tokens=False)\n",
    "    ground_truth_end_ind = indices.index(ground_truth_tokens[-1])\n",
    "    ground_truth_start_ind = ground_truth_end_ind - len(ground_truth_tokens) + 1\n",
    "\n",
    "    start_scores, end_scores = predict(input_ids, token_type_ids=token_type_ids, position_ids=position_ids, attention_mask=attention_mask)\n",
    "\n",
    "    print('Question: ', question)\n",
    "    print(start_scores)\n",
    "    print(end_scores)\n",
    "    print('Predicted Answer: ', ' '.join(all_tokens[torch.argmax(start_scores) : torch.argmax(end_scores)+1]))\n",
    "\n",
    "    attributions_start = nt.attribute(inputs=input_ids, nt_type='smoothgrad', n_samples=5, additional_forward_args=(token_type_ids, position_ids, attention_mask, 0))\n",
    "    attributions_end = nt.attribute(inputs=input_ids, nt_type='smoothgrad', n_samples=5, additional_forward_args=(token_type_ids, position_ids, attention_mask, 1))\n",
    "    \n",
    "    attributions_start_sum = summarize_attributions(attributions_start)\n",
    "    attributions_end_sum = summarize_attributions(attributions_end)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT-SQUAD.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
